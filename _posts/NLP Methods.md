---
layout: post
title: Stemming, Lemmatization, and Stop Words. Oh My!
---
![Alternate image text](/images/twitter/books.jpg)

I remember in high school English class looking at individual sentences and breaking it down into multiple ways. With a sentence written on the board, we identified part of speech for each word in order to understand how the words are applied in that sentence. We identified significant words and created meaning with those words, and we identified an emotion or underlining message when present in that sentence. Breaking down a sentence creates meaning. 

Natural Language Processing is part of the machine learning/AI pipeline, where a variety of tasks are applied in in order to process the text data and format it in a way so that the computer can read the data and perform analysis. 

![Alternate image text](/images/twitter/linguistics.png)

I love this figure which is taken from the textbook "Practical Natural Language Processing: A Comprehensive Guide to Building Real-World NLP Systems" by Vajjala, S. et al. 2020. The image shows the building blocks of a language and in result how NLP is utilized in order to process text data. Within the NLP packages, we can identify meaning through topic modelling and sentiment analysis. We can as well identify syntax through parsing words, morhpemes and lexemes through utilizing natural language tools such as tokenizing, word embeddings, and part of speach tagging, and identify speech and sounds from NLP applications such as speech to text, speaker identification, and text to speech. All of these NLP tools are important to think about when developing machine learning and AI models.